{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "cnn-simples-com-keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jscienciadados/CNN/blob/main/cnn_simples_com_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAlxCmT3X2bB"
      },
      "source": [
        "# Introdução"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFInyY2fX2bG"
      },
      "source": [
        "**Resumo:**\n",
        "\n",
        "O exemplo aqui desenvolvido tem como objetivo apresentar conceitos iniciais de implementação de redes neurais com python e tensorflow/keras. Esse modelo apresenta um modelo de Rede Neural Convolucional (CNN) básico que pode ser expandido mudando o número de neurônios e camadas. Em adaptações mais avançadas, pode-se estudar possibilidade de otimização de hyperparâmetros e outras técnincas como aumento de dados.\n",
        "\n",
        "**Não é objetivo nosso desenvolver e otimizar o modelo de classificação**. O exemplo tem objetivo meramente didático. para o proprio aprendizado.\n",
        "\n",
        "---\n",
        "\n",
        "**Para saber mais:**\n",
        "\n",
        "* François Chollet. Deep Learning with Python. Manning Publications, 2017.\n",
        "* Ian Goodfellow and Yoshua Bengio and Aaron Courville. [Deep Learning](https://www.deeplearningbook.org/). MIT Press, 2016."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utxFFULgaeAf"
      },
      "source": [
        "# Neste exemplo usarei o conjunto de dados de digitos digitados a mão, para classificá-lo usando uma rede CNN simples e obitive resultados impressionante com pouca transformação dos dados. Isso mostra o poder das redes neurais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dH6jKGWqX2bI"
      },
      "source": [
        "# Bibliotecas e Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-16T20:39:41.500258Z",
          "start_time": "2019-01-16T20:39:39.261856Z"
        },
        "trusted": true,
        "id": "Eoi4QYO8X2bJ"
      },
      "source": [
        "# Bibliotecas necessárias\n",
        "# Manipulação de dados\n",
        "import pandas as pd\n",
        "# Redes Neurais\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "# Avaliação\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wbCxcym1X2bK"
      },
      "source": [
        "# Lendo o dataset Kaggle -> este dataset foi obtido no kaggle uma plataforma de inteligecia artificial e competiçoes\n",
        "# usei o google colab com uma GPU -> pois para rodar com cpu leva muito tempo para ser processada.\n",
        "train = pd.read_csv(\"input/train.csv\")\n",
        "\n",
        "#Alternativa ler do próprio dataset do keras -> esse dataset tem 60000 exemplos \n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EMN-oMFFX2bL"
      },
      "source": [
        "# Analisando o dataset\n",
        "print(\"Quantidade de elementos de treino: {}\". format(len(train)))\n",
        "#print(train.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "VVQsf6CZX2bM"
      },
      "source": [
        "# Separando x_train e y_train\n",
        "Y = train[\"label\"]\n",
        "# O x contem todas a variaveis preditoras por isso excluimos a variavel label.\n",
        "X = train.drop(labels = [\"label\"],axis = 1)\n",
        "#print(X.head())\n",
        "# Outra alternativa possivel\n",
        "# Em formato numpy array de imagens 28 x 28\n",
        "#x = X.values.reshape(-1,28,28,1)\n",
        "#print(x[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "usENB19cX2bM"
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-08T20:49:47.144492Z",
          "start_time": "2019-01-08T20:49:47.016025Z"
        },
        "trusted": true,
        "id": "laEpG9ChX2bN"
      },
      "source": [
        "# Mostrando uma imagem com a biblioteca matplotlib\n",
        "plt.imshow(X.values[0].reshape(28,28), cmap=plt.cm.binary)\n",
        "plt.show()\n",
        "print('Label: {}'.format(Y[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-08T20:49:57.425537Z",
          "start_time": "2019-01-08T20:49:57.272377Z"
        },
        "trusted": true,
        "id": "jyx7tBOOX2bO"
      },
      "source": [
        "# Transformando a imagem 2d em um numpy array (imagem 28*28)\n",
        "x = X.values.reshape(42000, 28, 28, 1)\n",
        "\n",
        "#Normalizando para valores entre 0 e 1\n",
        "x = x.astype('float32')\n",
        "x /= 255\n",
        "\n",
        "#print(x[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-08T20:50:48.007428Z",
          "start_time": "2019-01-08T20:50:47.986527Z"
        },
        "trusted": true,
        "id": "k9z2AYpqX2bP"
      },
      "source": [
        "# Vamos ajustar o formato da saida\n",
        "num_classes = 10\n",
        "\n",
        "# Convertendo para um vetor de saida com 10 dimensoes\n",
        "# ex. 8 => [0,0,0,0,0,0,0,0,1,0]\n",
        "y = keras.utils.to_categorical(Y, num_classes)\n",
        "print(y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gIKOEu15X2bQ"
      },
      "source": [
        "# Separando uma parte para treino (90%) e outra para validação (10%)\n",
        "# usaremos 37800 exemplos para treino do modelo e 4200 exemplos para testes\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.1, random_state=5)\n",
        "print('Qtde de treino: {}'.format(len(x_train)))\n",
        "print('Qtde de validação: {}'.format(len(x_val)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0d9y7LX2bR"
      },
      "source": [
        "# Criando e treinando o Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-08T21:38:00.233865Z",
          "start_time": "2019-01-08T21:38:00.15079Z"
        },
        "scrolled": true,
        "trusted": true,
        "id": "-kFWVM8TX2bS"
      },
      "source": [
        "# Criando o modelo Sequential\n",
        "# Sequential: Modelo Keras de ir adicionando camadas (como um lego)\n",
        "# Conv2D: Camada com kernels (filtros) que percorrem a imagem extraindo caracterísitcas (mapas de caracteísticas)\n",
        "# MaxPooling2D: Camada que reduz a dimensionalidade dos mapas de características 2D\n",
        "# Flatten: Camada que transforma um mapa de características 2D num vetor para classficador final\n",
        "# Dense: Camada onde todas as entradas estão conectadas em cada neurônio (totalmente conectada)\n",
        "# Dropout: Camada usa durante treino que descarta aleatoriamente um percentual de conexões (reduz overfitting)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(200, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(100, kernel_size=(3,3), activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-08T21:33:17.184644Z",
          "start_time": "2019-01-08T21:33:17.129141Z"
        },
        "trusted": true,
        "id": "GKuw0wu3X2bT"
      },
      "source": [
        "# Compila o modelo\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-08T21:36:15.501168Z",
          "start_time": "2019-01-08T21:33:19.322895Z"
        },
        "trusted": true,
        "id": "1OP7nKisX2bT"
      },
      "source": [
        "# Treina com os parte dos dados\n",
        "batch_size = 32\n",
        "epochs = 50\n",
        "\n",
        "# Usamos um Callback para salvar o melhor modelo assim não precimos disperdiçar recursos da maquina.\n",
        "#Salvar o melhor modelo\n",
        "callbacks_list = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath='model.h5',\n",
        "        monitor='val_loss', save_best_only=True, verbose=1),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=10,verbose=1)\n",
        "]\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    callbacks = callbacks_list,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-08T21:36:20.243921Z",
          "start_time": "2019-01-08T21:36:20.064201Z"
        },
        "trusted": true,
        "id": "pkHf8KLdX2bU"
      },
      "source": [
        "#Vamos ver como foi o treino?\n",
        "\n",
        "fig, ax = plt.subplots(1,2, figsize=(16,8))\n",
        "ax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\n",
        "legend = ax[0].legend(loc='best', shadow=True)\n",
        "\n",
        "ax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "ax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "legend = ax[1].legend(loc='best', shadow=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "37dEY8d0X2bV"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "# Load the best saved model\n",
        "model = load_model('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-08T21:36:39.779842Z",
          "start_time": "2019-01-08T21:36:38.946173Z"
        },
        "trusted": true,
        "id": "FkpjWxOxX2bW"
      },
      "source": [
        "# Testa\n",
        "score = model.evaluate(x_val, y_val, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-08T21:06:04.363715Z",
          "start_time": "2019-01-08T21:06:04.27849Z"
        },
        "trusted": true,
        "id": "sksE6IxqX2bX"
      },
      "source": [
        "# Testando uma entrada qualquer\n",
        "print(y_train[10])\n",
        "print(model.predict(x_train[10].reshape((1,28,28,1))))\n",
        "print(model.predict_classes(x_train[10].reshape((1,28,28,1))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bif_boKJX2bY"
      },
      "source": [
        "# Avaliando o Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gyxYjpP3X2bY"
      },
      "source": [
        "import itertools\n",
        "\n",
        "#Plot the confusion matrix. Set Normalize = True/False\n",
        "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10,10))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        cm = np.around(cm, decimals=2)\n",
        "        cm[np.isnan(cm)] = 0.0\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2019-01-08T21:24:57.7654Z",
          "start_time": "2019-01-08T21:24:57.220867Z"
        },
        "trusted": true,
        "id": "HOK_Gp30X2bZ"
      },
      "source": [
        "# Vendo alguns reports# Vendo alguns reports\n",
        "# Usando sklearn\n",
        "import numpy as np\n",
        "\n",
        "# Classificando toda base de teste\n",
        "y_pred = model.predict_classes(x_val)\n",
        "# voltando pro formato de classes\n",
        "y_test_c = np.argmax(y_val, axis=1)\n",
        "target_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "\n",
        "#Confution Matrix\n",
        "cm = confusion_matrix(y_test_c, y_pred)\n",
        "plot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\n",
        "\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test_c, y_pred, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH5pjH3lX2bb"
      },
      "source": [
        "# Gerando Saída"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "TRtLBzeNX2bc"
      },
      "source": [
        "# Gerando saída para dataset de teste\n",
        "\n",
        "#Carrega dataset de teste\n",
        "test = pd.read_csv(\"input/test.csv\")\n",
        "print(\"Qtde de testes: {}\".format(len(test)))\n",
        "# transformando no formato numpy e normaliza\n",
        "x_test = test.values.reshape(len(test),28,28,1)\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255\n",
        "\n",
        "# Faz classificação para dataset de teste\n",
        "y_pred = model.predict_classes(x_test)\n",
        "\n",
        "# Verficando algum exemplo\n",
        "i = 0\n",
        "plt.imshow(test.values[i].reshape(28,28), cmap=plt.cm.binary)\n",
        "plt.show()\n",
        "print('Previsto: {}'.format(y_pred[i]))\n",
        "\n",
        "# Botando no formato de saída (competição Kaggle)\n",
        "results = pd.Series(y_pred,name=\"Label\")\n",
        "submission = pd.concat([pd.Series(range(1,len(y_pred)+1),name = \"ImageId\"),results],axis = 1)\n",
        "print(submission.head(10))\n",
        "#Salvando Arquivo\n",
        "submission.to_csv(\"mlp_mnist_v1.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCd3hNq9X2bd"
      },
      "source": [
        "# Teste Adicional: Com ruído"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LHnJbeWsX2bd"
      },
      "source": [
        "#introduzindo ruido\n",
        "import numpy as np\n",
        "mean = 0.\n",
        "stddev = 0.2\n",
        "noise = np.random.normal(mean, stddev, (4200, 28, 28,1))\n",
        "x_te = x_val + noise\n",
        "x_te = np.clip(x_te, 0., 1.)\n",
        "\n",
        "plt.imshow(x_te.reshape(4200, 28,28)[0], cmap=plt.cm.binary)\n",
        "plt.show()\n",
        "\n",
        "# Testa\n",
        "score = model.evaluate(x_te, y_val, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ChyuyNxX2be"
      },
      "source": [
        "Com ruído, percebemos que a acurácia dos exemplos de validação caiu, mas muito menos que o modelo MLP (Multi Layer Perceptron) clássico.\n",
        "Um modelo Convolucional (CNN) captura melhor regiões, ou padrões espaciais de pixels, tornando o modelo mais robusto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wdmR-WWQX2be"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}